<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Perceptron: The most simple form of an artificial neural network | doretox</title>
<meta name=keywords content="Neural Networks"><meta name=description content="Built of one single neural layer and a single neuron."><meta name=author content="doreox"><link rel=canonical href=https://doretox.github.io/posts/perceptron/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.b609c58d5c11bb90b1a54e04005d74ad1ddf22165eb79f5533967e57df9c3b50.css integrity="sha256-tgnFjVwRu5CxpU4EAF10rR3fIhZet59VM5Z+V9+cO1A=" rel="preload stylesheet" as=style><link rel=icon href=https://doretox.com/images/favicon-32.png><link rel=icon type=image/png sizes=16x16 href=https://doretox.com//images/favicon-16.png><link rel=icon type=image/png sizes=32x32 href=https://doretox.com//images/favicon-32.png><link rel=apple-touch-icon href=https://doretox.com//images/favicon-16.png><link rel=mask-icon href=https://doretox.com//images/favicon-16.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://doretox.github.io/posts/perceptron/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-166484777-1","auto"),ga("send","pageview"))</script><meta property="og:title" content="Perceptron: The most simple form of an artificial neural network"><meta property="og:description" content="Built of one single neural layer and a single neuron."><meta property="og:type" content="article"><meta property="og:url" content="https://doretox.github.io/posts/perceptron/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-07-19T00:00:00+05:30"><meta property="article:modified_time" content="2022-07-19T00:00:00+05:30"><meta property="og:site_name" content="doretox"><meta name=twitter:card content="summary"><meta name=twitter:title content="Perceptron: The most simple form of an artificial neural network"><meta name=twitter:description content="Built of one single neural layer and a single neuron."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://doretox.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Perceptron: The most simple form of an artificial neural network","item":"https://doretox.github.io/posts/perceptron/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Perceptron: The most simple form of an artificial neural network","name":"Perceptron: The most simple form of an artificial neural network","description":"Built of one single neural layer and a single neuron.","keywords":["Neural Networks"],"articleBody":"The Perceptron was created in 1958 by Rosenblatt, being the most simple form of an artificial neural network, built of one single neural layer and a single neuron. The following image shows how a perceptron works.\nFor inputs, we have a vector of values and a vector of weights. The computation of a single layer perceptron is performed over the calculation of the sum of the input vector each with the value multiplied by the corresponding element of the vector of the weights. The value displayed in the output will be the input of an activation function.\nThe activation function will return 0 or 1. If the return is 0 the neuron will not activate, if the result is 1 the neuron will activate. Down below you can see a simple code representation of a perceptron.\nimport numpy as np # if you change the first value to -1 in inputs, the step funcion will # return 0 and the neuron will not activate. inputs = np.array([1, 7, 5]) weights = np.array([0.8, 0.1, 0]) def multiply_and_sum(i, w): \"\"\"Multiply and sum all the inputs and weights.\"\"\" return i.dot(w) # dot product s = multiply_and_sum(inputs, weights) def step_function(sm): \"\"\"Determines if the neuron will activate or not.\"\"\" if sm \u003e= 1: return 1 return 0 r = step_function(s) print(r) ","wordCount":"216","inLanguage":"en","datePublished":"2022-07-19T00:00:00+05:30","dateModified":"2022-07-19T00:00:00+05:30","author":{"@type":"Person","name":"doreox"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://doretox.github.io/posts/perceptron/"},"publisher":{"@type":"Organization","name":"doretox","logo":{"@type":"ImageObject","url":"https://doretox.com/images/favicon-32.png"}}}</script></head><body class=dark id=top><header class=header><nav class=nav><div class=logo><a href=https://doretox.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://doretox.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><ul class=lang-switch><li>|</li></ul></div></div><ul id=menu><li><a href=https://doretox.github.io/archives title=Archive><span>Archive</span></a></li><li><a href=https://doretox.github.io/about/ title=About><span>About</span></a></li><li><a href=https://doretox.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://doretox.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://doretox.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Perceptron: The most simple form of an artificial neural network</h1><div class=post-description>Built of one single neural layer and a single neuron.</div><div class=post-meta><span title='2022-07-19 00:00:00 +0530 +0530'>July 19, 2022</span>&nbsp;·&nbsp;doreox</div></header><div class=post-content><p>The Perceptron was created in 1958 by Rosenblatt, being the most simple form of an artificial neural network, built of one single neural layer and a single neuron.
The following image shows how a perceptron works.</p><p><img loading=lazy src=/images/perceptron/perceptron.png alt=Perceptron></p><p>For inputs, we have a vector of values and a vector of weights. The computation of a single layer perceptron is performed over the calculation of the sum of the input vector each with the value multiplied by the corresponding element of the vector of the weights. The value displayed in the output will be the input of an activation function.</p><p>The activation function will return 0 or 1. If the return is 0 the neuron will not activate, if the result is 1 the neuron will activate.
Down below you can see a simple code representation of a perceptron.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># if you change the first value to -1 in inputs, the step funcion will</span>
</span></span><span class=line><span class=cl><span class=c1># return 0 and the neuron will not activate.</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>7</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>weights</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>multiply_and_sum</span><span class=p>(</span><span class=n>i</span><span class=p>,</span> <span class=n>w</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Multiply and sum all the inputs and weights.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>i</span><span class=o>.</span><span class=n>dot</span><span class=p>(</span><span class=n>w</span><span class=p>)</span>  <span class=c1># dot product</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>s</span> <span class=o>=</span> <span class=n>multiply_and_sum</span><span class=p>(</span><span class=n>inputs</span><span class=p>,</span> <span class=n>weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>step_function</span><span class=p>(</span><span class=n>sm</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Determines if the neuron will activate or not.&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>sm</span> <span class=o>&gt;=</span> <span class=mi>1</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>r</span> <span class=o>=</span> <span class=n>step_function</span><span class=p>(</span><span class=n>s</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>r</span><span class=p>)</span>
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://doretox.github.io/tags/neural-networks/>Neural Networks</a></li></ul><nav class=paginav><a class=prev href=https://doretox.github.io/posts/knowledge-get-started-infosec/><span class=title>« Prev</span><br><span>Essential areas of knowledge to get started in Cybersecurity</span>
</a><a class=next href=https://doretox.github.io/posts/the-hacking-methodology/><span class=title>Next »</span><br><span>The Hacking Methodology</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://doretox.github.io/>doretox</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>